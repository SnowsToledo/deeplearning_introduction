# üìö Primeira Lista de Exerc√≠cios de  Deep Learning

### üß† Hist√≥ria e Evolu√ß√£o
1. O que motivou o surgimento das redes neurais artificiais? Inspirando-se neste modelo, diversos pesquisadores tentaram simular o funcionamento do c√©rebro, principalmente o processo de aprendizagem por experi√™ncia, a fim de criar sistemas inteligentes capazes de realizar tarefas como classifica√ß√£o, reconhecimento de padr√µes, processamento de imagens, entre outras atividades.
2. Quem √© considerado o "pai" das redes neurais? Geoffrey Everest Hinton, um cientista da computa√ß√£o e psic√≥logo cognitivo brit√¢nico-canadense, √© mais conhecido por seu trabalho em redes neurais artificiais.
3. O que foi o Perceptron de Rosenblatt e qual era sua limita√ß√£o? Perceptron √© uma rede neural de camada √∫nica e um Perceptron de v√°rias camadas √© chamado de Rede Neural Artificial. A perceptron utiliza de valores de entrada que cada valor de entrada √© multiplicado pelo seu peso respectivo depois √© feito a somat√≥rio de cada multiplica√ß√£o, este valor √© comparado com um threshold, se ele for menor ou igual recebe uma classifica√ß√£o, se for maior recebe outra classifica√ß√£o
4. O que foi o "AI Winter" e por que ele aconteceu?  Foram per√≠odos em que as pesquisas no ramo da Intelig√™ncia artificial pararam de receber incentivo. Os motivos foram expectativas exageradas, Limita√ß√µes T√©cnicas, Relat√≥rio Lighthill, falta de Poder Computacional, Colapso do Mercado de M√°quinas LISP,  Limita√ß√µes dos Sistemas Especialistas, Cortes no Financiamento Governamental, Desilus√£o com as Promessas N√£o Cumpridas, Fim do Projeto de Quinta Gera√ß√£o do Jap√£o
5. Como o algoritmo de retropropaga√ß√£o (backpropagation) revolucionou o treinamento de redes? O backpropagation √© o algoritmo-chave que faz o treinamento de modelos profundos algo computacionalmente trat√°vel. Para as redes neurais modernas, ele pode tornar o treinamento com gradiente descendente at√© dez milh√µes de vezes mais r√°pido, em rela√ß√£o a uma implementa√ß√£o ing√™nua. Essa √© a diferen√ßa entre um modelo que leva algumas horas ou dias para treinar e e outro que poderia levar anos (sem exagero).
6. Em que d√©cada o algoritmo de backpropagation foi popularizado?  artigo de 1986 de David Rumelhart, Geoffrey Hinton e Ronald Williams.
7. Quais foram os marcos do ressurgimento do deep learning nos anos 2000? Com o aumento do poder computacional e a disponibilidade de grandes conjuntos de dados, que o Deep Learning realmente come√ßou a florescer. O termo ‚Äúaprendizagem profunda‚Äù come√ßa a ganhar popularidade ap√≥s um artigo de Geoffrey Hinton e Ruslan Salakhutdinov mostrar como uma rede neural de v√°rias camadas poderia ser pr√©-treinada uma camada por vez. Processamento de dados e as unidades de processamento de gr√°ficos (GPUs) se tornaram mais r√°pidos Redes Neurais Convolucionais (CNNs), Redes Neurais Recorrentes (RNNs) e Long Short-Term Memory (LSTM), Redes Adversariais Generativas (GANs) e Transformers e Aten√ß√£o
8. Qual a import√¢ncia do artigo de AlexNet (2012) para o deep learning moderno? O AlexNet foi um modelo de classifica√ß√£o de imagem que possu√≠a 650.000 neur√¥nios e teve um resultado extraordin√°rio na competi√ß√£o de imagem que chamou muita aten√ß√£o
9. O que permitiu o sucesso das redes profundas a partir da d√©cada de 2010?
10. Quais tecnologias contribu√≠ram para o avan√ßo do deep learning?

### üîç Conceitos Fundamentais
1. O que √© um neur√¥nio artificial?
2. Como uma rede neural aprende?
3. O que s√£o pesos e bias em uma rede?
4. O que √© uma fun√ß√£o de ativa√ß√£o? Cite 3 exemplos.
5. O que √© o overfitting? Como evit√°-lo?
6. Qual a diferen√ßa entre uma rede rasa e uma rede profunda?
7. O que √© o gradiente descendente?
8. Qual a diferen√ßa entre batch, mini-batch e online training?
9. O que √© uma fun√ß√£o de custo (loss function)?
10. Qual a diferen√ßa entre regress√£o e classifica√ß√£o em redes neurais?

### üß™ Treinamento e Otimiza√ß√£o
1. Como funciona o algoritmo de retropropaga√ß√£o?
2. O que √© o learning rate? Quais problemas ele pode causar?
3. Qual a fun√ß√£o do otimizador? Cite 3 exemplos.
4. O que s√£o √©pocas (epochs) e itera√ß√µes?
5. O que √© uma fun√ß√£o de ativa√ß√£o ReLU e por que ela √© popular?
6. Quais s√£o os problemas comuns do gradiente em redes profundas?
7. O que √© o problema do gradiente desaparecendo (vanishing gradient)?
8. Como a inicializa√ß√£o dos pesos pode afetar o treinamento?
9. O que √© regulariza√ß√£o L1 e L2?
10. O que √© dropout e qual seu prop√≥sito?

### üî¨ Arquiteturas e Modelos
1. O que √© uma MLP (Multilayer Perceptron)?
2. Como uma MLP se diferencia de uma rede linear simples?
3. O que define a capacidade de generaliza√ß√£o de uma MLP?
4. Qual o papel da n√£o-linearidade em uma MLP?
5. Como determinar o n√∫mero de camadas e neur√¥nios em uma MLP?
6. Por que redes profundas geralmente t√™m melhor desempenho que rasas?
7. O que √© backpropagation through layers?
8. Qual a rela√ß√£o entre MLPs e fun√ß√µes universais de aproxima√ß√£o?
9. Qual o impacto de usar uma fun√ß√£o de ativa√ß√£o linear em todas as camadas?
10. O que significa dizer que uma rede est√° subajustada (underfitting)?

### üß∞ Aplica√ß√µes e Casos Cl√°ssicos
1. Quais s√£o as principais aplica√ß√µes de MLPs?
2. Por que MLPs n√£o s√£o ideais para imagens e sequ√™ncias?
3. Como MLPs s√£o usados em sistemas de recomenda√ß√£o?
4. Quais os desafios de treinar MLPs com muitos par√¢metros?
5. Qual o papel do conjunto de valida√ß√£o no treinamento?
6. O que √© early stopping e quando utiliz√°-lo?
7. Como avaliar o desempenho de um modelo de classifica√ß√£o?
8. Como a normaliza√ß√£o dos dados afeta o desempenho da MLP?
9. O que √© uma matriz de confus√£o e como ela √© usada?
10. Como voc√™ explicaria o funcionamento de uma MLP para algu√©m leigo?

